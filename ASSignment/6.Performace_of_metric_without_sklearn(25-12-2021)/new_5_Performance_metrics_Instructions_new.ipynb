{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "\n",
    "## A. Compute performance metrics for the given data '5_a.csv'\n",
    " <pre>  <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)\n",
    "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba\n",
       "0  1.0  0.637387\n",
       "1  1.0  0.635165\n",
       "2  1.0  0.766586\n",
       "3  1.0  0.724564\n",
       "4  1.0  0.889199\n",
       "5  1.0  0.601600\n",
       "6  1.0  0.666323\n",
       "7  1.0  0.567012\n",
       "8  1.0  0.650230\n",
       "9  1.0  0.829346"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a=pd.read_csv('5_a.csv')\n",
    "df_a.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a['proba']=np.where(df_a['proba']>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    10100\n",
      "Name: proba, dtype: int64\n",
      "1.0    10000\n",
      "0.0      100\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_a['proba'].value_counts())# After replacing prob i.e predicted\n",
    "print(df_a['y'].value_counts()) # Before predicting y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a=df_a.rename(columns={'proba':'Y_pred'},inplace=False)# renaming proba as y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_confusion_matrix(df_a):\n",
    "    True_possitive=((df_a['y']==1) & (df_a['Y_pred']==1)).sum()\n",
    "    False_Negative=((df_a['y']==1) & (df_a['Y_pred']==0)).sum()\n",
    "    True_Negative=((df_a['y']==0) & (df_a['Y_pred']==0)).sum()\n",
    "    False_Possitive=((df_a['y']==0) & (df_a['Y_pred']==1)).sum()\n",
    "    confusion_matrix=[[True_Negative,False_Negative],\n",
    "                     [False_Possitive,True_possitive]]\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [100, 10000]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix=Get_confusion_matrix(df_a)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yg8uUJvGAfCM"
   },
   "outputs": [],
   "source": [
    "def f1_score(confusion_matrix):#Return F! function for a given confusion matrix\n",
    "    precision=(confusion_matrix[1][1])/(confusion_matrix[1][0]+confusion_matrix[1][1])\n",
    "    recall=(confusion_matrix[1][1])/(confusion_matrix[1][0]+confusion_matrix[1][1])\n",
    "    f1_score=(2*precision*recall/(precision+recall))\n",
    "    return f1_score\n",
    "    #print(precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900990099009901"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(confusion_matrix)#F1 score for a given confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "    acc=(cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [100, 10000]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix=Get_confusion_matrix(df_a)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(confusion_matrix):#Return F! function for a given confusion matrix\n",
    "    precision=(confusion_matrix[1][1])/(confusion_matrix[1][0]+confusion_matrix[1][1])\n",
    "    recall=(confusion_matrix[1][1])/(confusion_matrix[1][0]+confusion_matrix[1][1])\n",
    "    f1_score=(2*precision*recall/(precision+recall))\n",
    "    return f1_score\n",
    "    #print(precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900990099009901"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(confusion_matrix)#F1 score for a given confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "    acc=(cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def TPR_FPR(copy_df_a):\n",
    "    TPR=[]\n",
    "    FPR=[]\n",
    "    copy_df_a=copy_df_a.sort_values(by=['proba'],ascending=False)# dataset is sorted in descending order based on proba column\n",
    "    for thershold in tqdm(copy_df_a['proba'].unique()):\n",
    "        copy_df_a['Y_pred']=np.where(copy_df_a['proba']>=thershold,1,0)\n",
    "        cm=Get_confusion_matrix(copy_df_a)\n",
    "        tp=cm[1][1]\n",
    "        tn=cm[0][0]\n",
    "        fp=cm[1][0]\n",
    "        fn=cm[0][1]\n",
    "        TPR.append(tp/(tp+fn))\n",
    "        FPR.append(tn/(tn+fp))\n",
    "    return TPR,FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10100/10100 [00:32<00:00, 306.52it/s]\n"
     ]
    }
   ],
   "source": [
    "df_a=pd.read_csv('5_a.csv')\n",
    "TPR,FPR=TPR_FPR(df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488199\n"
     ]
    }
   ],
   "source": [
    "print(np.trapz(FPR,x=TPR))#0.48829900000000004 is the answer which i need to get but i got 0.488199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "\n",
    "\n",
    "## B. Compute performance metrics for the given data '5_b.csv'\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a>\n",
    "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba\n",
       "0  0.0  0.281035\n",
       "1  0.0  0.465152\n",
       "2  0.0  0.352793\n",
       "3  0.0  0.157818\n",
       "4  0.0  0.276648"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b=pd.read_csv('5_b.csv')\n",
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xlLVa-cVAfCS"
   },
   "outputs": [],
   "source": [
    "# write your code here for task B\n",
    "df_b['proba']=np.where(df_b['proba']>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9806\n",
      "1     294\n",
      "Name: proba, dtype: int64\n",
      "0.0    10000\n",
      "1.0      100\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_b['proba'].value_counts())# After replacing prob i.e predicted\n",
    "print(df_b['y'].value_counts()) # Before predicting y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9761, 45], [239, 55]]\n"
     ]
    }
   ],
   "source": [
    "#Getting confusion matrix from the above function Get_confusion_matrix\n",
    "df_b=df_b.rename(columns={'proba':'Y_pred'},inplace=False)# renaming proba as y_pred\n",
    "confusion_matrix_b=Get_confusion_matrix(df_b)\n",
    "print(confusion_matrix_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1870748299319728\n"
     ]
    }
   ],
   "source": [
    "#Getting f1 score with above function f1_score\n",
    "f1_score_b=f1_score(confusion_matrix_b)\n",
    "print(f1_score_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "#Getting acuuracy with the above function accuracy\n",
    "confusion_matrix_b=Get_confusion_matrix(df_b)\n",
    "print(accuracy(confusion_matrix_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10100/10100 [00:37<00:00, 272.09it/s]\n"
     ]
    }
   ],
   "source": [
    "df_b=pd.read_csv('5_b.csv')\n",
    "TPR_b,FPR_b=TPR_FPR(df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9277569999999999\n"
     ]
    }
   ],
   "source": [
    "print(np.trapz(FPR_b,TPR_b))# Given answer is 0.9377570000000001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "### C. Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data \n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [],
   "source": [
    "df_c=pd.read_csv('5_c.csv')\n",
    "df_c.rename(columns={'prob':'proba'},inplace=True)#Renaming prob column with prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eAPjewjzAfCa"
   },
   "outputs": [],
   "source": [
    " # write your code for task C\n",
    "df_c['proba']=np.where(df_c.proba>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2099\n",
      "1     753\n",
      "Name: proba, dtype: int64\n",
      "0    1805\n",
      "1    1047\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_c['proba'].value_counts())# Predicted points\n",
    "print(df_c['y'].value_counts())# Actual given points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1637, 462], [168, 585]]\n"
     ]
    }
   ],
   "source": [
    "#Getting confusion matrix with the function Get_confusion_matrix\n",
    "df_c=df_c.rename(columns={'proba':'Y_pred'},inplace=False)\n",
    "confusion_matrix_c=Get_confusion_matrix(df_c)\n",
    "print(confusion_matrix_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_A(temp_df,thershold):#Return A value as per the required condtion py taking thershold value along with the dataframe\n",
    "    temp_df['Y_pred']=np.where(temp_df.proba>thershold,1,0)\n",
    "    cm=Get_confusion_matrix(temp_df)\n",
    "    FP=cm[1][0]\n",
    "    FN=cm[0][1]\n",
    "    A=(500*FN)+(100*FP)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_calulated_values={}#USed to store all the A values in the form of dict with thershold, A as keyvalue pair\n",
    "df_c=pd.read_csv('5_c.csv')\n",
    "df_c.rename(columns={'prob':'proba'},inplace=True)\n",
    "df_c=df_c.drop_duplicates(subset=['proba'],keep='first',ignore_index=True)#Drop dupliates based on proba \n",
    "df_c.sort_values(by=['proba'],ascending=True,ignore_index=True,inplace=True)#sort the data based on proba coumn\n",
    "for i in range(len(df_c)):\n",
    "    thershold=df_c.loc[i,'proba']#pick each thershold values\n",
    "    A=find_A(df_c,thershold)#get A value from the function Find_A\n",
    "    c_calulated_values[thershold]=A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value(dct):# Get a value of thershold such that A is minimum\n",
    "    min_term=max(dct.values())\n",
    "    req=-1\n",
    "    for i,j in dct.items():\n",
    "        if j<=min_term:\n",
    "            min_term=j\n",
    "            req=i\n",
    "    return req,min_term\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2501259844850849, 140000)\n"
     ]
    }
   ],
   "source": [
    "print(get_min_value(c_calulated_values))\n",
    "#Lowest Thershold Value is 0.2501 and A value is around 140000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "\n",
    "## D.</b></font> Compute performance metrics(for regression) for the given data 5_d.csv\n",
    "<pre>    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "sVOj-bF9AfCd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred\n",
       "0  101.0  100.0\n",
       "1  120.0  100.0\n",
       "2  131.0  113.0\n",
       "3  164.0  125.0\n",
       "4  154.0  152.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d=pd.read_csv('5_d.csv')\n",
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "uRhL1pheAfCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.16569974554707\n"
     ]
    }
   ],
   "source": [
    " # write your code for task 5d\n",
    "MSE=0\n",
    "for i in range(len(df_d)):\n",
    "    y=df_d.loc[i,'y']\n",
    "    y_pred=df_d.loc[i,'pred']\n",
    "    sub=(y-y_pred)*(y-y_pred)\n",
    "    MSE=MSE+sub\n",
    "MSE=MSE/len(df_d)\n",
    "print(MSE)# mean square value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1291202994009687\n",
      "12.91202994009687\n"
     ]
    }
   ],
   "source": [
    "#mean Absolute percentage errror\n",
    "e=0\n",
    "a=0\n",
    "for i in range(len(df_d)):\n",
    "    y=df_d.loc[i,'y']\n",
    "    y_pred=df_d.loc[i,'pred']\n",
    "    temp=abs(y_pred-y)\n",
    "    e=e+temp\n",
    "    a=a+y\n",
    "MAPE=e/a\n",
    "print(MAPE)\n",
    "print(MAPE*100)# MAPE value less than 30 is always acceptable\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9563582786990964\n"
     ]
    }
   ],
   "source": [
    "#R squared values\n",
    "RR=0\n",
    "avg_y=sum(df_d['y'])/len(df_d['y'])\n",
    "sum_of_squares=0\n",
    "sum_of_resude=0\n",
    "for i in range(len(df_d)):\n",
    "    y=df_d.loc[i,'y']\n",
    "    y_pred=df_d.loc[i,'pred']\n",
    "    sum_of_squares=sum_of_squares+((y-avg_y)**2)\n",
    "    sum_of_resude=sum_of_resude + ((y-y_pred)**2)\n",
    "    \n",
    "RR=(1 - (sum_of_resude/sum_of_squares))\n",
    "print(RR)# RR value near to 1 is best model we have got around 0.95\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
